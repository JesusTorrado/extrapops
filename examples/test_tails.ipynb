{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing tails for fair generation\n",
    "Tests to ensures that high SNR events are fairly sampled:\n",
    "- Low-$z$\n",
    "- High $(m_1, m_2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import interpolate, optimize, integrate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import extrapops.constants as const"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-$z$\n",
    "Check that when generating with max high-$z$ of 1, we generate fairly between $z$-min and some small z after which fair generation is obvious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick inspection of the potentially-problematic region -- z_min to 0.02\n",
    "\n",
    "from extrapops.redshifts import _default_z_perdecade, sample_z, event_rate_persec\n",
    "\n",
    "z_min, z_max = 1e-5, 1\n",
    "\n",
    "test_redshift_params = {\n",
    "    \"z_range\": [z_min, z_max],\n",
    "    \"T_yr\": 10000,\n",
    "    \"merger_rate_model\": \"madau\",\n",
    "    \"merger_rate_params\": {\n",
    "        \"R_0\": 18, \"z_0\": 0, \"d\": 2.7, \"r\": -2.9, \"z_peak\": 1.86}\n",
    "}\n",
    "\n",
    "z_sample = sample_z(**test_redshift_params)\n",
    "\n",
    "z_max_test = 0.02\n",
    "\n",
    "low_z_sample = z_sample[np.where(z_sample < z_max_test)[0]]\n",
    "del z_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_zs = np.logspace(np.log10(z_min), np.log10(z_max_test), 500)\n",
    "pdf_z = lambda z: test_redshift_params[\"T_yr\"] * const.yr_s * event_rate_persec(z)\n",
    "\n",
    "plt.figure(figsize=(10, 5), facecolor=\"1\")\n",
    "plt.title(\"Zoom low z (noisier events)\")\n",
    "plt.hist(low_z_sample, density=True, bins=100, histtype=\"step\")\n",
    "plt.plot(low_zs, pdf_z(low_zs) / len(low_z_sample))\n",
    "plt.loglog()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strange result, but see tests below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extrapops.redshifts import _invCDF_interpolator\n",
    "\n",
    "# Find x mapped to right bound\n",
    "func_to_minimize = lambda x: np.abs(interpolate.splev(x, _invCDF_interpolator) - z_max_test)\n",
    "sol = optimize.minimize(func_to_minimize, 1e-5, method='L-BFGS-B')\n",
    "x_of_z_max_test = sol[\"x\"][0]\n",
    "z_approx = interpolate.splev(x_of_z_max_test, _invCDF_interpolator)\n",
    "assert np.abs(z_approx - z_max_test) < 1e-3\n",
    "print(f\"{x_of_z_max_test=} maps to {z_approx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST #1: behaviour of numpy.random.random below this x_of_z_max_test,\n",
    "#          when sampling over the whole interval\n",
    "\n",
    "n_samples_uniform = int(5000 / x_of_z_max_test)\n",
    "samples_uniform = np.random.random(n_samples_uniform)\n",
    "low_x_samples = samples_uniform[np.where(samples_uniform < x_of_z_max_test)[0]]\n",
    "del samples_uniform\n",
    "\n",
    "print(\"This should be a uniform distribution!\")\n",
    "plt.figure(figsize=(10, 5), facecolor=\"1\")\n",
    "plt.hist(low_x_samples)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST #2: the interpolator works as expected in the interval z_min to z_max_test\n",
    "\n",
    "xs = np.logspace(-18, np.log10(x_of_z_max_test), 100)\n",
    "zs = interpolate.splev(xs, _invCDF_interpolator)\n",
    "\n",
    "# recompute CDF at a few points with a different algorithm\n",
    "z_subsample = np.logspace(np.log10(z_min), np.log10(z_max_test), 5000)\n",
    "# add the last point to normalize the cdf\n",
    "z_subsample = list(z_subsample) + [z_max]\n",
    "dx_integral = 1e-7\n",
    "ints = [(lambda zs: integrate.simps(pdf_z(zs), zs))(np.arange(z_min, z_int, dx_integral))\n",
    "        for z_int in z_subsample[1:]]\n",
    "ints = np.array([0] + list(ints))\n",
    "CDF_samples = (ints - min(ints)) / (max(ints) - min(ints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Both sets should fall on top of each other!\")\n",
    "plt.figure(figsize=(10, 5), facecolor=\"1\")\n",
    "plt.plot(xs, zs, \".-\", label=\"Interpolator\")\n",
    "plt.plot(CDF_samples[:-1], z_subsample[:-1], \"o\", label=\"Recomputed integral\")\n",
    "plt.loglog()\n",
    "plt.ylabel(\"Redshift\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks ok!\n",
    "# Notice from the initial inspection that generating events with z<1e-3 is very unlikely,\n",
    "# so this last test should be enough!\n",
    "\n",
    "# We are generating in the low-z tail correctly!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High $(m_1, m_2)$\n",
    "### (Can be run independently from 1st part, except 1st import cell)\n",
    "We'll test the methods used by default: invCDF for $m_1$, and rejection sampling for $m_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extrapops.mass import sample_m1_m2, pdf_m1, pdf_m1_m2, _default_mass_params\n",
    "from extrapops.redshifts import avg_n_events\n",
    "\n",
    "# Let's use the default parameters. Where exactly m_max is should not matter too much.\n",
    "\n",
    "m_min_test = 80\n",
    "assert m_min_test < _default_mass_params[\"m_range\"][1], \\\n",
    "    f\"Need m_min_test smaller than upper mass bound {_default_mass_params['m_range'][1]}!\"\n",
    "\n",
    "n_samples = int(avg_n_events() / 1)\n",
    "m1, m2 = sample_m1_m2(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1\n",
    "\n",
    "m_log10range = np.log10(_default_mass_params[\"m_range\"])\n",
    "m1s = np.logspace(np.log10(m_min_test), np.log10(_default_mass_params[\"m_range\"][1]), 10000)\n",
    "\n",
    "nbins = 1000\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(m1s, pdf_m1(m1s), label=r\"$P(m_1)$\")\n",
    "plt.hist(m1, density=True, bins=nbins, histtype=\"step\",\n",
    "         label=\"sample\")\n",
    "plt.legend()\n",
    "plt.title(\"m1 sample\")\n",
    "plt.xlim(m_min_test, _default_mass_params[\"m_range\"][1] * 1.02)\n",
    "plt.loglog()\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks OK for m1!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m2\n",
    "\n",
    "# we first need p(m2)\n",
    "print(\"Marginalising over m1 to get pdf(m2)...\")\n",
    "# To avoid hitting 0's in the probability, start from m_min + eps\n",
    "m_min_int = _default_mass_params[\"m_range\"][0] + 1e-10\n",
    "# To avoid integrating a long null tail, cut the upper bound\n",
    "m_max_int = 0.9999 * _default_mass_params[\"m_range\"][1]\n",
    "ms_marg = np.logspace(np.log10(m_min_test), np.log10(m_max_int), 50, base=10)\n",
    "pdf_m2_marg_m1 = np.array(\n",
    "    [integrate.quad(lambda m1: pdf_m1_m2(m1, m2), m_min_int, m_max_int, limit=1000)[0]\n",
    "     for m2 in ms_marg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 500\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(ms_marg, pdf_m2_marg_m1, \".-\", label=r\"$P(m_2)$\")\n",
    "plt.hist(m2, density=True, bins=nbins, histtype=\"step\", label=\"sample\")\n",
    "plt.legend()\n",
    "plt.title(\"m2 sample\")\n",
    "plt.xlim(m_min_test, _default_mass_params[\"m_range\"][1] * 1.02)\n",
    "plt.loglog()\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK for m2 too! (the \"decay\" in the pdf is bc of the upper integration limit for the marginalisation)\n",
    "\n",
    "# Probably the problematic boundary here is m_min, which does not matter too much,\n",
    "# either for observable events or the background."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
